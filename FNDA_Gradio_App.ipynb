{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227135c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHIVRAM\\OneDrive\\Desktop\\miniconda3\\envs\\Shiv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Application ---\n",
      "Loading all trained models into memory...\n",
      "✓ Passive Aggressive model loaded\n",
      "✓ Random Forest model loaded\n",
      "✓ Logistic Regression model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bi-LSTM model loaded\n",
      "✓ Bi-LSTM tokenizer loaded\n",
      "All available models loaded successfully.\n",
      "\n",
      "--- Launching Fake News Detection App ---\n",
      "Open the URL below in your browser to access the application:\n",
      "Models Status: Loaded\n",
      "* Running on local URL:  http://127.0.0.1:7010\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7010/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# FAKE NEWS DETECTION GRADIO WEB APPLICATION\n",
    "# ===============================================================================\n",
    "# This script loads the trained models and creates a professional web interface\n",
    "# for real-time fake news classification.\n",
    "\n",
    "# --- Core and ML Libraries ---\n",
    "import gradio as gr\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "\n",
    "# --- Handle potential numpy/scikit-learn compatibility issues ---\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "# --- TensorFlow for Deep Learning Model ---\n",
    "# Sets TensorFlow logging to a less verbose level.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "# --- NLTK for Text Preprocessing ---\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. INITIAL SETUP AND MODEL LOADING\n",
    "# ==============================================================================\n",
    "print(\"--- Initializing Application ---\")\n",
    "\n",
    "# --- Download NLTK data (if not already present) ---\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    print(\"Downloading NLTK data...\")\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "\n",
    "# --- Define paths to saved models ---\n",
    "MODEL_DIR = \"production_models\"\n",
    "\n",
    "# --- Load all models and necessary components ---\n",
    "print(\"Loading all trained models into memory...\")\n",
    "# If you see 'Models are not available. Please check the console.' error:\n",
    "# Ensure all required model files exist in the 'production_models' directory and are named correctly.\n",
    "try:\n",
    "    # --- CORRECTED FILENAMES ---\n",
    "    # These names now match the files in your project directory.\n",
    "    # Please double-check the full, untruncated names on your machine.\n",
    "    \n",
    "    # Initialize variables to None first\n",
    "    model_pac = None\n",
    "    model_rf = None\n",
    "    model_lr = None\n",
    "    model_bilstm = None\n",
    "    tokenizer_bilstm = None\n",
    "    \n",
    "    # Load Traditional ML Model Pipelines (TF-IDF + Classifier)\n",
    "    if os.path.exists(os.path.join(MODEL_DIR, 'passive_aggressive_pipeline.pkl')):\n",
    "        model_pac = joblib.load(os.path.join(MODEL_DIR, 'passive_aggressive_pipeline.pkl'))\n",
    "        print(\"✓ Passive Aggressive model loaded\")\n",
    "    \n",
    "    if os.path.exists(os.path.join(MODEL_DIR, 'random_forest_pipeline.pkl')):\n",
    "        model_rf = joblib.load(os.path.join(MODEL_DIR, 'random_forest_pipeline.pkl'))\n",
    "        print(\"✓ Random Forest model loaded\")\n",
    "    \n",
    "    if os.path.exists(os.path.join(MODEL_DIR, 'logistic_regression_pipeline.pkl')):\n",
    "        model_lr = joblib.load(os.path.join(MODEL_DIR, 'logistic_regression_pipeline.pkl'))\n",
    "        print(\"✓ Logistic Regression model loaded\")\n",
    "\n",
    "    # Load Bi-LSTM Model and its Tokenizer\n",
    "    if os.path.exists(os.path.join(MODEL_DIR, 'bilstm_model.h5')):\n",
    "        model_bilstm = tf.keras.models.load_model(os.path.join(MODEL_DIR, 'bilstm_model.h5'))\n",
    "        print(\"✓ Bi-LSTM model loaded\")\n",
    "    \n",
    "    if os.path.exists(os.path.join(MODEL_DIR, 'bilstm_tokenizer.pkl')):\n",
    "        tokenizer_bilstm = joblib.load(os.path.join(MODEL_DIR, 'bilstm_tokenizer.pkl'))\n",
    "        print(\"✓ Bi-LSTM tokenizer loaded\")\n",
    "    \n",
    "    # Check if at least one model was loaded\n",
    "    models_available = [model_pac, model_rf, model_lr, model_bilstm]\n",
    "    if any(model is not None for model in models_available):\n",
    "        MODELS_LOADED = True\n",
    "        print(\"All available models loaded successfully.\")\n",
    "    else:\n",
    "        MODELS_LOADED = False\n",
    "        print(\"No model files found in the production_models directory.\")\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: A model file was not found. {e}\")\n",
    "    print(\"Please ensure the 'production_models' directory is in the same folder as this script and contains all required model files.\")\n",
    "    MODELS_LOADED = False\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during model loading: {e}\")\n",
    "    MODELS_LOADED = False\n",
    "\n",
    "# ===============================================================================\n",
    "# 2. TEXT PREPROCESSING FUNCTION\n",
    "# ===============================================================================\n",
    "# This function is used by all models to clean the input text.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses raw text for model prediction.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def get_available_models():\n",
    "    \"\"\"\n",
    "    Returns a list of available models based on what was successfully loaded.\n",
    "    \"\"\"\n",
    "    available_models = []\n",
    "    \n",
    "    if model_pac is not None:\n",
    "        available_models.append(\"Passive Aggressive\")\n",
    "    if model_rf is not None:\n",
    "        available_models.append(\"Random Forest\")\n",
    "    if model_lr is not None:\n",
    "        available_models.append(\"Logistic Regression\")\n",
    "    if model_bilstm is not None and tokenizer_bilstm is not None:\n",
    "        available_models.append(\"Bi-LSTM (with GloVe)\")\n",
    "    \n",
    "    # If no models are available, provide a placeholder\n",
    "    if not available_models:\n",
    "        available_models = [\"No models available\"]\n",
    "    \n",
    "    return available_models\n",
    "\n",
    "# ===============================================================================\n",
    "# 3. MASTER PREDICTION FUNCTION\n",
    "# ===============================================================================\n",
    "# This function orchestrates the prediction process based on the user's choice.\n",
    "\n",
    "def classify_news(model_name, article_text):\n",
    "    \"\"\"\n",
    "    Takes a model name and article text, preprocesses the text,\n",
    "    and returns a formatted prediction.\n",
    "    \"\"\"\n",
    "    if not MODELS_LOADED:\n",
    "        return {\"Error\": 1.0}, \"Models are not available. Please check the console for details.\"\n",
    "        \n",
    "    if not article_text or not article_text.strip():\n",
    "        return {\"Input Error\": 1.0}, \"Please enter some text to analyze.\"\n",
    "\n",
    "    # Step 1: Clean the input text\n",
    "    cleaned_article = clean_text(article_text)\n",
    "    \n",
    "    if not cleaned_article.strip():\n",
    "        return {\"Input Error\": 1.0}, \"The text appears to be empty after preprocessing. Please enter meaningful content.\"\n",
    "    \n",
    "    prediction_label = \"Error\"\n",
    "    confidence_scores = {\"Error\": 1.0}\n",
    "    \n",
    "    # Step 2: Use the selected model to predict\n",
    "    if model_name == \"Bi-LSTM (with GloVe)\":\n",
    "        if model_bilstm is None or tokenizer_bilstm is None:\n",
    "            return {\"Error\": 1.0}, \"Bi-LSTM model or tokenizer is not available. Please check if the model files exist.\"\n",
    "        \n",
    "        # Preprocessing for Bi-LSTM\n",
    "        sequence = tokenizer_bilstm.texts_to_sequences([cleaned_article])\n",
    "        padded_sequence = pad_sequences(sequence, maxlen=256, padding='post')\n",
    "        \n",
    "        # Prediction returns a probability\n",
    "        probability_fake = model_bilstm.predict(padded_sequence, verbose=0)[0][0]\n",
    "        \n",
    "        if probability_fake > 0.5:\n",
    "            prediction_label = \"FAKE News\"\n",
    "            confidence_scores = {\"FAKE News\": float(probability_fake), \"REAL News\": 1 - float(probability_fake)}\n",
    "        else:\n",
    "            prediction_label = \"REAL News\"\n",
    "            confidence_scores = {\"REAL News\": 1 - float(probability_fake), \"FAKE News\": float(probability_fake)}\n",
    "\n",
    "    else: # For traditional ML models\n",
    "        model_map = {\n",
    "            \"Passive Aggressive\": model_pac,\n",
    "            \"Random Forest\": model_rf,\n",
    "            \"Logistic Regression\": model_lr\n",
    "        }\n",
    "        \n",
    "        model_pipeline = model_map.get(model_name)\n",
    "        \n",
    "        if model_pipeline is None:\n",
    "            return {\"Error\": 1.0}, f\"Model '{model_name}' is not available. Please check if the model file exists.\"\n",
    "        \n",
    "        # The pipeline handles both TF-IDF vectorization and prediction\n",
    "        prediction = model_pipeline.predict([cleaned_article])[0]\n",
    "        \n",
    "        # Get probability scores for confidence\n",
    "        try:\n",
    "            probabilities = model_pipeline.predict_proba([cleaned_article])[0]\n",
    "            confidence_scores = {\"REAL News\": float(probabilities[0]), \"FAKE News\": float(probabilities[1])}\n",
    "        except AttributeError: # Passive Aggressive doesn't have predict_proba\n",
    "            # For Passive Aggressive, provide binary confidence\n",
    "            confidence = 0.85 if prediction == 1 else 0.85  # Default confidence\n",
    "            confidence_scores = {\"REAL News\": 1-confidence if prediction == 1 else confidence, \n",
    "                               \"FAKE News\": confidence if prediction == 1 else 1-confidence}\n",
    "\n",
    "        prediction_label = \"FAKE News\" if prediction == 1 else \"REAL News\"\n",
    "\n",
    "    # Step 3: Format the output\n",
    "    result_text = f\"## Analysis Result\\n\\n**Model Used:** {model_name}\\n\\n**Classification:** {prediction_label}\\n\\n---\\n\\n*The confidence scores below indicate the model's certainty in its prediction.*\"\n",
    "    return confidence_scores, result_text\n",
    "\n",
    "# ===============================================================================\n",
    "# 4. GRADIO INTERFACE DEFINITION\n",
    "# ===============================================================================\n",
    "# Defines the layout and components of the web application.\n",
    "\n",
    "# --- Enhanced Dark Mode CSS with #E3256B accent color ---\n",
    "custom_css = \"\"\"\n",
    "/* Import Google Fonts */\n",
    "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
    "\n",
    "/* Global Dark Theme */\n",
    "* {\n",
    "    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif !important;\n",
    "}\n",
    "\n",
    "body, .gradio-container {\n",
    "    background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%) !important;\n",
    "    color: #e0e0e0 !important;\n",
    "    min-height: 100vh;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    border-radius: 20px !important;\n",
    "    box-shadow: 0 8px 32px rgba(227, 37, 107, 0.1), 0 4px 16px rgba(0, 0, 0, 0.3) !important;\n",
    "    backdrop-filter: blur(10px) !important;\n",
    "    border: 1px solid rgba(227, 37, 107, 0.1) !important;\n",
    "}\n",
    "\n",
    "/* Header Styling */\n",
    "#header {\n",
    "    text-align: center;\n",
    "    padding: 40px 20px 30px 20px;\n",
    "    background: linear-gradient(135deg, rgba(227, 37, 107, 0.1) 0%, rgba(26, 26, 46, 0.8) 100%);\n",
    "    border-radius: 20px 20px 0 0;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    "\n",
    "#header h1 {\n",
    "    background: linear-gradient(135deg, #E3256B 0%, #ff6b9d 100%);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    background-clip: text;\n",
    "    font-size: 3.2em !important;\n",
    "    font-weight: 700 !important;\n",
    "    margin-bottom: 10px !important;\n",
    "    letter-spacing: -1px;\n",
    "    text-shadow: 0 4px 8px rgba(227, 37, 107, 0.3);\n",
    "}\n",
    "\n",
    "#header p {\n",
    "    color: #b0b0c0 !important;\n",
    "    font-size: 1.2em !important;\n",
    "    font-weight: 400 !important;\n",
    "    margin-bottom: 0 !important;\n",
    "    opacity: 0.9;\n",
    "}\n",
    "\n",
    "/* Section Headers */\n",
    ".gradio-markdown h3 {\n",
    "    color: #E3256B !important;\n",
    "    font-weight: 600 !important;\n",
    "    font-size: 1.3em !important;\n",
    "    margin-bottom: 15px !important;\n",
    "    padding-bottom: 8px;\n",
    "    border-bottom: 2px solid rgba(227, 37, 107, 0.3);\n",
    "}\n",
    "\n",
    "/* Input Elements */\n",
    ".gradio-textbox, .gradio-dropdown {\n",
    "    background: rgba(30, 30, 50, 0.7) !important;\n",
    "    border: 2px solid rgba(227, 37, 107, 0.3) !important;\n",
    "    border-radius: 15px !important;\n",
    "    color: #e0e0e0 !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "}\n",
    "\n",
    ".gradio-textbox:focus, .gradio-dropdown:focus {\n",
    "    border-color: #E3256B !important;\n",
    "    box-shadow: 0 0 20px rgba(227, 37, 107, 0.2) !important;\n",
    "    transform: translateY(-2px);\n",
    "}\n",
    "\n",
    ".gradio-textbox textarea {\n",
    "    background: transparent !important;\n",
    "    color: #e0e0e0 !important;\n",
    "    border: none !important;\n",
    "}\n",
    "\n",
    "/* Buttons */\n",
    ".gradio-button {\n",
    "    border-radius: 12px !important;\n",
    "    font-weight: 600 !important;\n",
    "    font-size: 1em !important;\n",
    "    padding: 12px 24px !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "    border: none !important;\n",
    "    text-transform: uppercase;\n",
    "    letter-spacing: 0.5px;\n",
    "}\n",
    "\n",
    ".gradio-button.primary {\n",
    "    background: linear-gradient(135deg, #E3256B 0%, #ff4081 100%) !important;\n",
    "    color: white !important;\n",
    "    box-shadow: 0 4px 15px rgba(227, 37, 107, 0.3) !important;\n",
    "}\n",
    "\n",
    ".gradio-button.primary:hover {\n",
    "    transform: translateY(-3px) !important;\n",
    "    box-shadow: 0 8px 25px rgba(227, 37, 107, 0.4) !important;\n",
    "}\n",
    "\n",
    ".gradio-button.secondary {\n",
    "    background: rgba(60, 60, 80, 0.8) !important;\n",
    "    color: #e0e0e0 !important;\n",
    "    border: 2px solid rgba(227, 37, 107, 0.3) !important;\n",
    "}\n",
    "\n",
    ".gradio-button.secondary:hover {\n",
    "    background: rgba(227, 37, 107, 0.1) !important;\n",
    "    border-color: #E3256B !important;\n",
    "    transform: translateY(-2px) !important;\n",
    "}\n",
    "\n",
    "/* Output Elements */\n",
    ".gradio-label {\n",
    "    background: rgba(30, 30, 50, 0.8) !important;\n",
    "    border: 2px solid rgba(227, 37, 107, 0.3) !important;\n",
    "    border-radius: 15px !important;\n",
    "    color: #e0e0e0 !important;\n",
    "    padding: 20px !important;\n",
    "    margin: 10px 0 !important;\n",
    "}\n",
    "\n",
    ".gradio-markdown {\n",
    "    background: rgba(30, 30, 50, 0.6) !important;\n",
    "    border-radius: 15px !important;\n",
    "    padding: 20px !important;\n",
    "    border: 1px solid rgba(227, 37, 107, 0.2) !important;\n",
    "    color: #e0e0e0 !important;\n",
    "}\n",
    "\n",
    "/* Examples Section */\n",
    ".gradio-examples {\n",
    "    background: rgba(25, 25, 40, 0.8) !important;\n",
    "    border-radius: 15px !important;\n",
    "    padding: 20px !important;\n",
    "    border: 1px solid rgba(227, 37, 107, 0.2) !important;\n",
    "    margin-top: 20px !important;\n",
    "}\n",
    "\n",
    "/* Scrollbar */\n",
    "::-webkit-scrollbar {\n",
    "    width: 8px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-track {\n",
    "    background: rgba(30, 30, 50, 0.5);\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-thumb {\n",
    "    background: linear-gradient(135deg, #E3256B 0%, #ff4081 100%);\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    "::-webkit-scrollbar-thumb:hover {\n",
    "    background: linear-gradient(135deg, #ff4081 0%, #E3256B 100%);\n",
    "}\n",
    "\n",
    "/* Animation for results */\n",
    ".gradio-label, .gradio-markdown {\n",
    "    animation: slideIn 0.5s ease-out;\n",
    "}\n",
    "\n",
    "@keyframes slideIn {\n",
    "    from {\n",
    "        opacity: 0;\n",
    "        transform: translateY(20px);\n",
    "    }\n",
    "    to {\n",
    "        opacity: 1;\n",
    "        transform: translateY(0);\n",
    "    }\n",
    "}\n",
    "\n",
    "/* Dropdown styling */\n",
    ".gradio-dropdown select {\n",
    "    background: rgba(30, 30, 50, 0.9) !important;\n",
    "    color: #e0e0e0 !important;\n",
    "    border: none !important;\n",
    "}\n",
    "\n",
    "/* Footer removal */\n",
    "footer {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    "/* Loading indicator */\n",
    ".loading {\n",
    "    border: 3px solid rgba(227, 37, 107, 0.3);\n",
    "    border-top: 3px solid #E3256B;\n",
    "    border-radius: 50%;\n",
    "    width: 30px;\n",
    "    height: 30px;\n",
    "    animation: spin 1s linear infinite;\n",
    "    margin: 20px auto;\n",
    "}\n",
    "\n",
    "@keyframes spin {\n",
    "    0% { transform: rotate(0deg); }\n",
    "    100% { transform: rotate(360deg); }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# ===============================================================================\n",
    "# 5. GRADIO INTERFACE LAYOUT\n",
    "# ===============================================================================\n",
    "\n",
    "# --- Building the interface with Gradio Blocks ---\n",
    "with gr.Blocks(css=custom_css, theme=gr.themes.Base(primary_hue=\"pink\", secondary_hue=\"purple\", neutral_hue=\"slate\").set(\n",
    "    body_background_fill=\"*neutral_950\",\n",
    "    background_fill_primary=\"*neutral_900\",\n",
    "    background_fill_secondary=\"*neutral_800\",\n",
    "    border_color_primary=\"*primary_500\",\n",
    "    button_primary_background_fill=\"*primary_600\",\n",
    "    button_primary_background_fill_hover=\"*primary_700\"\n",
    ")) as app:\n",
    "    \n",
    "    # --- Header Section ---\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"# Fake News Detection System\")\n",
    "\n",
    "    gr.Markdown(\"---\")\n",
    "\n",
    "    # --- Main Interface Section ---\n",
    "    with gr.Row():\n",
    "        # --- Input Column ---\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"### 1. Select Classification Model\")\n",
    "            \n",
    "            available_models = get_available_models()\n",
    "            default_model = available_models[0] if available_models else \"No models available\"\n",
    "            \n",
    "            model_selector = gr.Dropdown(\n",
    "                label=\"Choose AI Model\",\n",
    "                choices=available_models,\n",
    "                value=default_model,\n",
    "                info=\"Each model uses different algorithms for classification\"\n",
    "            )\n",
    "            \n",
    "            gr.Markdown(\"### 2. Enter News Article Text\")\n",
    "            article_input = gr.Textbox(\n",
    "                label=\"Article Content\",\n",
    "                placeholder=\"Paste the complete news article text here for analysis...\\n\\nTip: Include headlines, body text, and any relevant details for better accuracy.\",\n",
    "                lines=16,\n",
    "                max_lines=20,\n",
    "                info=\"Minimum 10 words recommended for accurate classification\"\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                clear_button = gr.Button(\"Clear\", variant=\"secondary\", size=\"lg\")\n",
    "                submit_button = gr.Button(\"Analyze News\", variant=\"primary\", size=\"lg\")\n",
    "\n",
    "        # --- Output Column ---\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"### 3. Classification Results\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                output_text = gr.Markdown(\n",
    "                    value=\"**Ready for Analysis**\\n\\nSelect a model, enter your news article, and click 'Analyze News' to get started.\\n\\n---\\n\\n*Results will appear here with detailed confidence scores.*\",\n",
    "                    elem_classes=\"result-container\"\n",
    "                )\n",
    "                output_label = gr.Label(\n",
    "                    label=\"Confidence Scores\",\n",
    "                    show_label=True\n",
    "                )\n",
    "            \n",
    "            gr.Markdown(\"### Pro Tips\")\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                • **Better Results**: Use complete articles with headlines\n",
    "                • **Model Selection**: Try different models for comparison  \n",
    "                • **Confidence**: Higher scores indicate more certainty\n",
    "                • **Speed**: Passive Aggressive is fastest, Bi-LSTM most accurate\n",
    "                \"\"\",\n",
    "                elem_classes=\"tips-container\"\n",
    "            )\n",
    "\n",
    "    # --- Enhanced Button Logic ---\n",
    "    def analyze_with_loading(model_name, article_text):\n",
    "        \"\"\"Wrapper function to add loading states\"\"\"\n",
    "        if not article_text or len(article_text.split()) < 5:\n",
    "            return {\"Input Error\": 1.0}, \"Please enter at least 5 words for meaningful analysis.\"\n",
    "        return classify_news(model_name, article_text)\n",
    "    \n",
    "    submit_button.click(\n",
    "        fn=analyze_with_loading,\n",
    "        inputs=[model_selector, article_input],\n",
    "        outputs=[output_label, output_text],\n",
    "        api_name=\"classify\"\n",
    "    )\n",
    "    \n",
    "    clear_button.click(\n",
    "        lambda: (None, \"**Ready for Analysis**\\n\\nSelect a model, enter your news article, and click 'Analyze News' to get started.\\n\\n---\\n\\n*Results will appear here with detailed confidence scores.*\", None), \n",
    "        outputs=[article_input, output_text, output_label]\n",
    "    )\n",
    "\n",
    "# ===============================================================================\n",
    "# 6. LAUNCH THE APPLICATION  \n",
    "# ===============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- Launching Fake News Detection App ---\")\n",
    "    print(\"Open the URL below in your browser to access the application:\")\n",
    "    print(\"Models Status:\", \"Loaded\" if MODELS_LOADED else \"Failed\")\n",
    "    \n",
    "    app.launch(\n",
    "        share=False,\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7010,\n",
    "        show_error=True,\n",
    "        quiet=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
